{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9dbc0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c9dbc0a",
        "outputId": "b6c1ec43-0c28-4499-eebf-4753d055c55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
            "14630912/14628807 [==============================] - 0s 0us/step\n",
            "14639104/14628807 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/SiiHyunn/DipLearning_2021/main/test.txt\n",
            "16384/588 [===================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "path_to_test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/SiiHyunn/DipLearning_2021/main/test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71dad779",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71dad779",
        "outputId": "bb0201e8-3d73-4a2c-9a6a-748f02b0d945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫눈이 오는걸 보고있으니까 기분이 몽글몽글하네요. 모두들 따뜻하게 입었으면 좋겠습니다. 길가에 있는 고양이도 행복했으면 좋겠습니다.\t1\n",
            "좋아하는 발라드가수의 신곡을 들어봤습니다. 예전 앨범과 달리 멜로디라인이 마음에 안들었습니다. 긴 공백기에 비해 부족한 앨범이였습니다.\t0\n",
            "오늘 쌀국수를 먹었습니다. 대기줄이 길어서 힘들었습니다. 하지만 먹고나니까 기다린 시간이 아깝지않았습니다. 힘줄 쌀국수를 꼭 먹어보셔야합니다.\t1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
        "test_text = open(path_to_test_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85df4257",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85df4257",
        "outputId": "5cdc1bbe-1ba3-4b28-ffa3-97775d472f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150000, 1) (3, 1)\n",
            "[[1]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "test_Y = np.array([[int(row.split('\\t')[1])] for row in test_text.split('\\n')[0:] if row.count('\\t') > 0])\n",
        "print(train_Y.shape, test_Y.shape)\n",
        "print(test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4783c86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4783c86",
        "outputId": "546f3d32-d755-42ce-a38f-85275d260dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['첫눈이', '오는걸', '보고있으니까', '기분이', '몽글몽글하네요', '모두들', '따뜻하게', '입었으면', '좋겠습니다', '길가에', '있는', '고양이도', '행복했으면', '좋겠습니다']\n",
            "['좋아하는', '발라드가수의', '신곡을', '들어봤습니다', '예전', '앨범과', '달리', '멜로디라인이', '마음에', '안들었습니다', '긴', '공백기에', '비해', '부족한', '앨범이였습니다']\n",
            "['오늘', '쌀국수를', '먹었습니다', '대기줄이', '길어서', '힘들었습니다', '하지만', '먹고나니까', '기다린', '시간이', '아깝지않았습니다', '힘줄', '쌀국수를', '꼭', '먹어보셔야합니다']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_str(string):    \n",
        "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "\n",
        "    return string\n",
        "\n",
        "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "train_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
        "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
        "test_text_X = [row.split('\\t')[0] for row in test_text.split('\\n')[0:] if row.count('\\t') > 0]\n",
        "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
        "test_sentences = [sentence.split(' ') for sentence in test_text_X]\n",
        "\n",
        "for i in range(3):\n",
        "    test_sentences[i].pop() #뒤에 공백 제거\n",
        "    print(test_sentences[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74846935",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74846935",
        "outputId": "16677f00-e255-4b08-8ff5-e86bd73e3eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['첫눈이', '오는걸', '보고있으니', '기분이', '몽글몽글하', '모두들', '따뜻하게', '입었으면', '좋겠습니다', '길가에', '있는', '고양이도', '행복했으면', '좋겠습니다']\n",
            "['좋아하는', '발라드가수', '신곡을', '들어봤습니', '예전', '앨범과', '달리', '멜로디라인', '마음에', '안들었습니', '긴', '공백기에', '비해', '부족한', '앨범이였습']\n",
            "['오늘', '쌀국수를', '먹었습니다', '대기줄이', '길어서', '힘들었습니', '하지만', '먹고나니까', '기다린', '시간이', '아깝지않았', '힘줄', '쌀국수를', '꼭', '먹어보셔야']\n"
          ]
        }
      ],
      "source": [
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "    sentences_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentences_new\n",
        "\n",
        "test_sentences_new = []\n",
        "for sentence in test_sentences:\n",
        "    test_sentences_new.append([word[:5] for word in sentence][:25])\n",
        "test_sentences = test_sentences_new\n",
        "\n",
        "for i in range(3):\n",
        "    print(test_sentences[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7190200",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7190200",
        "outputId": "8af1d7a7-2888-490f-c441-986206d71294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  891  5505  4454  2268    41 19663  2268     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  193  1638  2065   383  1021   403   727     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  310  8391    68 12066   150    61     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "train_X = tokenizer.texts_to_sequences(sentences)\n",
        "train_X = pad_sequences(train_X, padding='post')\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_X = pad_sequences(test_X,padding='post', maxlen=25)\n",
        "\n",
        "print(test_X[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736ab7c5",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "736ab7c5",
        "outputId": "cf344fda-f8d2-4249-ff26-a11bd0723245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 50)                70200     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,070,302\n",
            "Trainable params: 6,070,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 17s 16ms/step - loss: 0.4352 - accuracy: 0.7828 - val_loss: 0.3833 - val_accuracy: 0.8198\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 0.3256 - accuracy: 0.8480 - val_loss: 0.3889 - val_accuracy: 0.8165\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 0.2736 - accuracy: 0.8679 - val_loss: 0.4124 - val_accuracy: 0.8148\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 0.2319 - accuracy: 0.8853 - val_loss: 0.4608 - val_accuracy: 0.8137\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 0.1976 - accuracy: 0.9018 - val_loss: 0.5453 - val_accuracy: 0.8056\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(20000, 300, input_length=25),\n",
        "    tf.keras.layers.LSTM(units=50),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbb210c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fbb210c",
        "outputId": "e6c79619-1965-4c39-a960-ac3bdb7ccf8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0129 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0128615228459239, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.evaluate(test_X, test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75db2024",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75db2024",
        "outputId": "4ff0d342-4e19-48d3-f4ab-2717b7c00354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기분이\n",
            "잊혀질\n",
            "[[], [19999], [], [106]]\n",
            "[[    0]\n",
            " [19999]\n",
            " [    0]\n",
            " [  106]]\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.index_word[891])\n",
        "print(tokenizer.index_word[20000])\n",
        "temp = tokenizer.texts_to_sequences(['#$#$#', '경우는', '잊혀질', '연기가'])\n",
        "print(temp)\n",
        "temp = pad_sequences(temp, padding='post')\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b71927",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2b71927",
        "outputId": "ae45faeb-8979-4114-b330-289ff6458739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['재미있을']\n",
            "[0.44421503 0.55578494]\n",
            "['재미있을', '줄']\n",
            "[0.44285986 0.5571402 ]\n",
            "['재미있을', '줄', '알았는데']\n",
            "[0.49538654 0.50461346]\n",
            "['재미있을', '줄', '알았는데', '완전']\n",
            "[0.47859922 0.52140075]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.']\n",
            "[0.47859922 0.52140075]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무']\n",
            "[0.663353   0.33664694]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고']\n",
            "[0.99119943 0.00880056]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이']\n",
            "[0.99872786 0.00127214]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이', '아까웠다.']\n",
            "[0.99872786 0.00127214]\n"
          ]
        }
      ],
      "source": [
        "test_sentence = '재미있을 줄 알았는데 완전 실망했다. 너무 졸리고 돈이 아까웠다.'\n",
        "test_sentence = test_sentence.split(' ')\n",
        "test_sentences = []\n",
        "now_sentence = []\n",
        "for word in test_sentence:\n",
        "    now_sentence.append(word)\n",
        "    test_sentences.append(now_sentence[:])\n",
        "    \n",
        "test_X_1 = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_X_1 = pad_sequences(test_X_1, padding='post', maxlen=25)\n",
        "prediction = model.predict(test_X_1)\n",
        "for idx, sentence in enumerate(test_sentences):\n",
        "    print(sentence)\n",
        "    print(prediction[idx])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Sp5uZimtPa",
        "outputId": "e9148b9f-11ef-4716-bbb3-c493ecf9ab50"
      },
      "id": "S8Sp5uZimtPa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41d7d2df",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41d7d2df",
        "outputId": "c4a3627a-6f4d-4d8e-9719-eec44ff78319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of train.zip or\n",
            "        train.zip.zip, and cannot find train.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "!unzip train.zip -d /content/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27210a84",
      "metadata": {
        "id": "27210a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f521cf3-93d6-41de-8ca5-6c7ebb76bda4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 id             breed\n",
            "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
            "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
            "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
            "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
            "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10222 entries, 0 to 10221\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      10222 non-null  object\n",
            " 1   breed   10222 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 159.8+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "label_text = pd.read_csv('labels.csv')\n",
        "print(label_text.head())\n",
        "label_text.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8d10fa",
      "metadata": {
        "id": "4d8d10fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abcc76f-3047-4f97-eefc-dc6dc910feb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "label_text['breed'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for c in range(9):\n",
        "  image_id = label_text.loc[c, 'id']\n",
        "  plt.subplot(3, 3, c+1)\n",
        "  plt.imshow(plt.imread('/content/train/' + image_id + '.jpg'))\n",
        "  plt.title(str(c) + ', ' + label_text.loc[c, 'breed'])\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "0Fv0LVsSoWrx",
        "outputId": "3f5968a8-edf7-4e09-f514-b9c8bf46d559"
      },
      "id": "0Fv0LVsSoWrx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9ab0a836e90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/train/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'breed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1462\u001b[0m             raise ValueError('Only know how to handle PNG; with Pillow '\n\u001b[1;32m   1463\u001b[0m                              'installed, Matplotlib can handle more images')\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train/000bec180eb18c7604dcecc8fe0dba07.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "mobilev2 = MobileNetV2()\n",
        "\n",
        "for layer in mobilev2.layers[:-1]:\n",
        "  layer.trainable = True\n",
        "\n",
        "for layer in mobilev2.layers[:-1]:\n",
        "  if 'kernel' in layer.__dict__:\n",
        "    kernel_shape = np.array(layer.get_weights()).shape\n",
        "    layer.set_weights(tf.random.normal(kernel_shape, 0, 1))"
      ],
      "metadata": {
        "id": "idbvR7A0pkwD"
      },
      "id": "idbvR7A0pkwD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.mkdir('/content/train_sub')\n",
        "\n",
        "for i in range(len(label_text)):\n",
        "    if os.path.exists('/content/train_sub/' + label_text.loc[i]['breed']) == False:\n",
        "        os.mkdir('/content/train_sub/' + label_text.loc[i]['breed'])\n",
        "    shutil.copy('/content/train/' + label_text.loc[i]['id'] + '.jpg', '/content/train_sub/' + label_text.loc[i]['breed'])"
      ],
      "metadata": {
        "id": "M2l4bnadqpcF"
      },
      "id": "M2l4bnadqpcF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "\n",
        "image_size = 299\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255., horizontal_flip=True, shear_range=0.2, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, validation_split=0.25)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255., validation_split=0.25)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=\"/content/train_sub/\", subset=\"training\", batch_size=batch_size, seed=42, shuffle=True, class_mode=\"categorical\", target_size=(image_size, image_size))\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=\"/content/train_sub/\", subset=\"validation\", batch_size=1, seed=42, shuffle=True, class_mode=\"categorical\", target_size=(image_size, image_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvKKeIzFsFhi",
        "outputId": "0278513e-adbc-44a6-cdba-c1e4388fccc9"
      },
      "id": "fvKKeIzFsFhi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7718 images belonging to 120 classes.\n",
            "Found 2504 images belonging to 120 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_Y = label_text['breed'].unique().tolist()\n",
        "train_Y = [unique_Y.index(breed) for breed in label_text['breed']]\n",
        "train_Y = np.array(train_Y)\n",
        "\n",
        "print(train_Y[:10])\n",
        "print(train_Y[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9PIrjsIsOvx",
        "outputId": "10ce08eb-b146-42bd-d5fc-f64b52fd4154"
      },
      "id": "B9PIrjsIsOvx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 5 6 7 8]\n",
            "[34 87 91 63 48  6 93 63 77 92]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = mobilev2.layers[-2].output\n",
        "predictions = tf.keras.layers.Dense(120, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=mobilev2.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "steps_per_epoch = int(7718/32)\n",
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=10, steps_per_epoch=steps_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "q7syPUTvshat",
        "outputId": "e528d579-84b4-4a17-aad1-2977a2b4203c"
      },
      "id": "q7syPUTvshat",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-828f8982a5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7718\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0, 0.1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vrehytf0tAe-"
      },
      "id": "vrehytf0tAe-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "mobilev2 = MobileNetV2()\n",
        "\n",
        "x = mobilev2.layers[-2].output\n",
        "predictions = tf.keras.layers.Dense(120, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=mobilev2.input, outputs=predictions)\n",
        "\n",
        "for layer in model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) # 라벨이 원-핫 인코딩을 사용하기 때문에 sparse가 아닌 categorical_crossentropy를 사용합니다.\n",
        "model.summary()\n",
        "\n",
        "steps_per_epoch = int(7718/32)\n",
        "history = model.fit_generator(train_generator, validation_data=valid_generator,epochs=10, steps_per_epoch=steps_per_epoch)"
      ],
      "metadata": {
        "id": "xfJzKyHktBrP"
      },
      "id": "xfJzKyHktBrP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_image_path = ['/content/sample/1.PNG',\n",
        "                  '/content/sample/2.PNG',\n",
        "                  '/content/sample/3.PNG',\n",
        "                  '/content/sample/4.PNG',\n",
        "                  '/content/sample/5.PNG',]"
      ],
      "metadata": {
        "id": "zLZW4rk4EvJs"
      },
      "id": "zLZW4rk4EvJs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import random\n",
        "plt.figure(figsize=(16,16))\n",
        "  \n",
        "for c in range(5):\n",
        "    image_path = all_image_path[c]\n",
        "    \n",
        "    plt.subplot(5,2,c*2+1)\n",
        "    plt.imshow(plt.imread(image_path))\n",
        "    real_y = image_path.split('/')[3]\n",
        "    plt.title(real_y)\n",
        "    plt.axis('off')\n",
        "    idx = unique_sorted_Y.index(real_y)\n",
        "    \n",
        "    plt.subplot(5,2,c*2+2)\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, dsize=(299, 299))\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    \n",
        "    feature_vector = feature_model.predict(img)\n",
        "    \n",
        "    prediction = model.predict(feature_vector)[0]\n",
        "    \n",
        "    top_5_predict = prediction.argsort()[::-1][:5]\n",
        "    labels = [unique_sorted_Y[index] for index in top_5_predict]\n",
        "    color = ['gray'] * 5\n",
        "    if idx in top_5_predict:\n",
        "        color[top_5_predict.tolist().index(idx)] = 'green'\n",
        "    color = color[::-1]\n",
        "    plt.barh(range(5), prediction[top_5_predict][::-1] * 100, color=color)\n",
        "    plt.yticks(range(5), labels[::-1])"
      ],
      "metadata": {
        "id": "SCm_KshwtHPD"
      },
      "id": "SCm_KshwtHPD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Assignment_04.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}