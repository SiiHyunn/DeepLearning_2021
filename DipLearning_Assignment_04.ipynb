{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c9dbc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
    "path_to_test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/SiiHyunn/DipLearning_2021/main/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71dad779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫눈이 오는걸 보고있으니까 기분이 몽글몽글하네요. 모두들 따뜻하게 입었으면 좋겠습니다. 길가에 있는 고양이도 행복했으면 좋겠네요.\t1\n",
      "좋아하는 발라드가수의 신곡을 들어봤습니다. 예전 앨범과 달리 멜로디라인이 마음에 안들었습니다. 긴 공백기에 비해 부족했던 앨범이였습니다.\t0\n",
      "오늘 쌀국수를 먹었습니다. 대기줄이 길어서 힘들었습니다. 하지만 먹고나니까 기다린 시간이 아깝지않았습니다. 힘줄 쌀국수를 꼭 먹어보셔야합니다.\t1\n"
     ]
    }
   ],
   "source": [
    "train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
    "test_text = open(path_to_test_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85df4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 1) (3, 1)\n",
      "[[1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
    "test_Y = np.array([[int(row.split('\\t')[1])] for row in test_text.split('\\n')[0:] if row.count('\\t') > 0])\n",
    "print(train_Y.shape, test_Y.shape)\n",
    "print(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4783c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['첫눈이', '오는걸', '보고있으니까', '기분이', '몽글몽글하네요', '모두들', '따뜻하게', '입었으면', '좋겠습니다', '길가에', '있는', '고양이도', '행복했으면', '좋겠네요']\n",
      "['좋아하는', '발라드가수의', '신곡을', '들어봤습니다', '예전', '앨범과', '달리', '멜로디라인이', '마음에', '안들었습니다', '긴', '공백기에', '비해', '부족했던', '앨범이였습니다']\n",
      "['오늘', '쌀국수를', '먹었습니다', '대기줄이', '길어서', '힘들었습니다', '하지만', '먹고나니까', '기다린', '시간이', '아깝지않았습니다', '힘줄', '쌀국수를', '꼭', '먹어보셔야합니다']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_str(string):    \n",
    "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "\n",
    "    return string\n",
    "\n",
    "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
    "train_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
    "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
    "test_text_X = [row.split('\\t')[0] for row in test_text.split('\\n')[0:] if row.count('\\t') > 0]\n",
    "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
    "test_sentences = [sentence.split(' ') for sentence in test_text_X]\n",
    "\n",
    "for i in range(3):\n",
    "    test_sentences[i].pop() #뒤에 공백 왜 있지,,\n",
    "    print(test_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "74846935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['첫눈이', '오는걸', '보고있으니', '기분이', '몽글몽글하', '모두들', '따뜻하게', '입었으면', '좋겠습니다', '길가에', '있는', '고양이도', '행복했으면', '좋겠네요']\n",
      "14\n",
      "['좋아하는', '발라드가수', '신곡을', '들어봤습니', '예전', '앨범과', '달리', '멜로디라인', '마음에', '안들었습니', '긴', '공백기에', '비해', '부족했던', '앨범이였습']\n",
      "15\n",
      "['오늘', '쌀국수를', '먹었습니다', '대기줄이', '길어서', '힘들었습니', '하지만', '먹고나니까', '기다린', '시간이', '아깝지않았', '힘줄', '쌀국수를', '꼭', '먹어보셔야']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "sentences_new = []\n",
    "for sentence in sentences:\n",
    "    sentences_new.append([word[:5] for word in sentence][:25])\n",
    "sentences = sentences_new\n",
    "\n",
    "test_sentences_new = []\n",
    "for sentence in test_sentences:\n",
    "    test_sentences_new.append([word[:5] for word in sentence][:25])\n",
    "test_sentences = test_sentences_new\n",
    "\n",
    "for i in range(3):\n",
    "    print(test_sentences[i])\n",
    "    print(len(test_sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7190200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25  884    8 5795 1111    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 588 5796 6697    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[  891  5505  4454  2268    41 19663  1754]\n",
      " [  193  1638  2065   383  1021   403 13106]\n",
      " [  310  8391    68 12066   150    61     0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "train_X = tokenizer.texts_to_sequences(sentences)\n",
    "train_X = pad_sequences(train_X, padding='post')\n",
    "\n",
    "test_X = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_X = pad_sequences(test_X, padding='post')\n",
    "\n",
    "print(train_X[:3])\n",
    "print(test_X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "41d7d2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip -uq \"train.zip\" -d \"content/train\"\n",
    "!unzip -uq \"test.zip\" -d \"content/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a254faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'user_id' # 독자의 캐글 ID\n",
    "os.environ['KAGGLE_KEY'] = 'user_api_token' # 독자의 캐글 API Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d13fba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1cd86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
